{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17cb5b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Damir\\nymeria_dataset\\.pixi\\envs\\default\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys,torch,torchvision\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.transforms import ToTensor,Normalize,Compose\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from nymeria.data_provider import NymeriaDataProvider\n",
    "from nymeria.recording_data_provider import AriaStream\n",
    "from nymeria.xsens_constants import XSensConstants\n",
    "from projectaria_tools.core.stream_id import StreamId\n",
    "from projectaria_tools.core.sophus import SE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d12763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bones_to_unique_joints(b):\n",
    "    p=np.zeros((XSensConstants.num_parts,3),np.float32)\n",
    "    for i,(c,pa) in enumerate(b):\n",
    "        p[i+1]=c\n",
    "        if i==0:p[0]=pa\n",
    "    return p\n",
    "class TimeAlignedLoader:\n",
    "    def __init__(self,dp,fps=10,down=True):\n",
    "        self.dp=dp;self.down=down;self.dt=int(1e9/fps);self.t0,self.t1=dp.timespan_ns\n",
    "        r=dp.recording_head\n",
    "        self.sid=StreamId(AriaStream.camera_rgb.value)\n",
    "        self.vrs=r.vrs_dp\n",
    "        self.cam=self.vrs.get_device_calibration().get_camera_calib(\"camera-rgb\")\n",
    "        self.n=int((self.t1-self.t0)//self.dt)\n",
    "    def world_to_camera(self,P,Twd,Tdc):\n",
    "        Rwd=Twd.rotation().to_matrix();twd=Twd.translation().reshape(3)\n",
    "        Rdc=Tdc.rotation().to_matrix();tdc=Tdc.translation().reshape(3)\n",
    "        Rwc=Rwd@Rdc;twc=Rwd@tdc+twd\n",
    "        return (Rwc.T@(P.T-twc[:,None])).T\n",
    "    def __len__(self):return self.n\n",
    "    def __getitem__(self,i):\n",
    "        t=self.t0+i*self.dt\n",
    "        rgb=self.dp.get_synced_rgb_videos(t)[\"recording_head\"][0].to_numpy_array()\n",
    "        if self.down:rgb=rgb[::2,::2]\n",
    "        rgb=torch.from_numpy(rgb).permute(2,0,1).float()/255\n",
    "        poses=self.dp.get_synced_poses(t)\n",
    "        jw=bones_to_unique_joints(poses[\"xsens\"])\n",
    "        jw=jw-jw[0]\n",
    "        jw=torch.from_numpy(jw.reshape(-1)).float()\n",
    "        return rgb,jw\n",
    "class EgocentricPoseDataset(Dataset):\n",
    "    def __init__(self,seq_dir,fps=10,down=True,tf=None):\n",
    "        self.dp=NymeriaDataProvider(sequence_rootdir=Path(seq_dir),load_wrist=False,load_observer=False)\n",
    "        self.loader=TimeAlignedLoader(self.dp,fps,down)\n",
    "        self.tf=tf if tf else Compose([Normalize(0.5,0.5)])\n",
    "    def __len__(self):return len(self.loader)\n",
    "    def __getitem__(self,i):\n",
    "        img,j3d=self.loader[i]\n",
    "        img=self.tf(img)\n",
    "        return img,j3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e66077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        m=torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        m.fc=torch.nn.Linear(512,69)\n",
    "        self.net=m\n",
    "    def forward(self,x):return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e54c142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-18 02:09:21.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mloading xsens from npzfile='C:\\\\Users\\\\Damir\\\\nymeria_dataset\\\\d\\\\20230622_s0_john_solomon_act2_8urygm\\\\body\\\\xdata.npz'\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='segment_qWXYZ', v.shape=(144289, 92)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='segment_tXYZ', v.shape=(144289, 69)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='segment_velocity', v.shape=(144289, 69)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='segment_acceleration', v.shape=(144289, 69)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='segment_angularVelocity', v.shape=(144289, 69)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='segment_angularAcceleration', v.shape=(144289, 69)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='foot_contacts', v.shape=(144289, 4)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='sensor_qWXYZ', v.shape=(144289, 68)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='sensor_freeAcceleration', v.shape=(144289, 51)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='joint_angleEulerZXY', v.shape=(144289, 66)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='timestamps_us', v.shape=(144289,)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='frame_index', v.shape=(144289,)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='identity_segment_qWXYZ', v.shape=(92,)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='identity_segment_tXYZ', v.shape=(69,)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='tpose_segment_qWXYZ', v.shape=(92,)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='tpose_segment_tXYZ', v.shape=(69,)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='tpose-isb_segment_qWXYZ', v.shape=(92,)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='tpose-isb_segment_tXYZ', v.shape=(69,)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='segmentCount', v.shape=(1,)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='sensorCount', v.shape=(1,)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='jointCount', v.shape=(1,)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='frameRate', v.shape=(1,)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mk='frameCount', v.shape=(1,)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.544\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__correct_timestamps\u001b[0m:\u001b[36m65\u001b[0m - \u001b[33m\u001b[1mnumber of invalid timestamps 6, percentage=np.float64(0.004158321147142194)%\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:22.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36m__correct_timestamps\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mafter correct t_diff[-1]= np.int64(4296)us\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:25.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.data_provider\u001b[0m:\u001b[36m__get_timespan_ns\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mtime span: t_start= 3847697100000us t_end= 4446894896000us duration= 599.197796s\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:25.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.data_provider\u001b[0m:\u001b[36m__compute_xsens_to_aria_alignment\u001b[0m:\u001b[36m217\u001b[0m - \u001b[1mcompute alignment from xsens head to aria headset\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:25.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnymeria.body_motion_provider\u001b[0m:\u001b[36mget_T_w_h\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mget 143328 samples for computing alignment\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:40.117\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnymeria.handeye\u001b[0m:\u001b[36mso3xR3\u001b[0m:\u001b[36m36\u001b[0m - \u001b[34m\u001b[1mA.shape=(3, 143326), B.shape=(3, 143326)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:40.225\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnymeria.handeye\u001b[0m:\u001b[36mso3xR3\u001b[0m:\u001b[36m41\u001b[0m - \u001b[34m\u001b[1mmatrixU.shape=(3, 3), S.shape=(3,), matrixVh.shape=(3, 3)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:41.720\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnymeria.handeye\u001b[0m:\u001b[36mso3xR3\u001b[0m:\u001b[36m51\u001b[0m - \u001b[34m\u001b[1mjacobian.shape=(429978, 3)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:43.381\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnymeria.handeye\u001b[0m:\u001b[36mso3xR3\u001b[0m:\u001b[36m58\u001b[0m - \u001b[34m\u001b[1mresidual.shape=(429978, 1)\u001b[0m\n",
      "\u001b[32m2025-05-18 02:09:43.441\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnymeria.handeye\u001b[0m:\u001b[36mso3xR3\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1mT_A_B=array([[ 0.03052879, -0.06998607, -0.99708071,  0.0688561 ],\n",
      "       [-0.64812185,  0.75802483, -0.07305082,  0.03089059],\n",
      "       [ 0.76092448,  0.64845995, -0.02221792, -0.12410255]])\n",
      "\u001b[0m\n",
      "epoch 1/10:   0%|          | 0/375 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seq=r\"C:\\Users\\Damir\\nymeria_dataset\\d\\20230622_s0_john_solomon_act2_8urygm\"\n",
    "ds=EgocentricPoseDataset(seq,fps=10,down=True,tf=Compose([Normalize(0.5,0.5)]))\n",
    "dl=DataLoader(ds,batch_size=16,shuffle=True,num_workers=0)\n",
    "model=PoseNet().to(device)\n",
    "opt=torch.optim.AdamW(model.parameters(),1e-4)\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "epochs=10\n",
    "for epoch in range(1,epochs+1):\n",
    "    running=0\n",
    "    for img,j in tqdm(dl,desc=f\"epoch {epoch}/{epochs}\",leave=False):\n",
    "        img,j=img.to(device),j.to(device)\n",
    "        pred=model(img)\n",
    "        loss=loss_fn(pred,j)\n",
    "        opt.zero_grad();loss.backward();opt.step()\n",
    "        running+=loss.item()*img.size(0)\n",
    "    print(f\"epoch {epoch}: loss {running/len(ds):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
